The Message Passing Interface (MPI) is by far the dominant paradigm to write parallel HPC applications.
Given the prominence of message-passing programs in the portfolio of the HPC, communication among tasks is an important aspect to consider in Lazy Shadowing.
The communication model used in Lazy Shadowing assumes that the underlying 
hardware consists in a collection of cores connected through a high-speed 
network. 
%A specific number ($N+K$ or 2$N$, depending on the shadow mechanism employed) is used to run an 
%application of $N$ tasks. 
Each pair of cores running a main and its shadow 
are conceptually connected through a channel that respects First-in-first-out 
(FIFO) ordering. Therefore, two messages between the same source and 
destination can never be reordered. 
%Note that communicating tasks are an essential part of Lazy Shadowing giving the prominence of message-passing programs in the portfolio of the HPC. 

%An application using Lazy Shadowing requires an 
%infrastructure which ensures that any execution (even in the presence of failures) 
%finishes with correct results. That includes: a) a protocol to keep a shadow 
%task consistent with its main task, b) a mechanism to store the necessary 
%amount of messages, c) a fault detection and notification mechanism and d) a recovery method that %ensures the system 
%reaches a consistent state after a failure.

%The fundamental problem to address is to prevent a main M(i) and its shadow S(i) from diverging in their states. Shadow S(i) will typically lag behind M(i) during execution, so it is necessary to ensure that S(i) reaches the same states as M(i) in case of a failure. 
A shadow process will typically lag behind its main process during execution, so it is necessary to ensure that the shadow reaches the same states as its main in case of a failure. 
We will use a message-logging protocol~\cite{Marz} to satisfy that requirement. This type of protocols use meta-information to store and replicate the non-deterministic decisions in the execution of an application. %For example, if main tasks M(j) and M(k) send messages $m_j$ and $m_k$ to M(i), the same two messages should reach S(i). In this project, we will explore a few alternatives to guarantee this property. Since message reception is, in general, non deterministic, the order in which M(i) processes $m_j$ and $m_k$ has to be replicated by S(i). 
%Otherwise, shadow S(i) may deviate from the state at M(i) (keep in mind that floating-point arithmetic is non associative). 
With few bits of information, message-logging protocols are able to maintain the consistency requiements. These pieces of information, also called determinants, are sent through system-level messages. In addition, we must highlight that shadows are mute in the sense that 
all outgoing messages from shadows are suppressed. 

To provide correct recovery after failure, 
a mechanism is required to guarantee that every shadow process follows the same computation and communication steps as its main process. 
After a main process M(i) fails, S(i) will take over M(i)'s role to recover from this failure. If there are other shadows sharing the same core with S(i), they will be terminated and S(i)
will start consuming the messages in its receiver-side message log at a faster speed. The message logging protocol will ensure that shadow S(i), now a main process, reaches a consistent state with the rest of the system. 

During the execution of a tightly coupled application, the remaining main processes are forced to stop execution and wait idly while S(i) is recovering. This leads to potential performance degradation which is similar to (but much slighter than) the scalability issue of checkpointing and roll back recovery. To mitigate this problem, in the following we propose a mechanism that takes advantage of the waiting time and roll forward all the shadows to the state of their corresponding mains.
Another potential problem is that the size of the message queues is likely to keep growing (message creation is faster than its consumption), since a shadow process executes slower than its main. Correspondingly, an efficient strategy to reduce the size of the receiver-side message log will be discussed.
%We will use the strategy of forced shadow leaping that will be described in the next section and exploit application patterns to avoid storing all messages.
