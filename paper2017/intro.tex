Computing power of supercomputers has become a vital factor in determing a country's competiveness in research, technology, and even national defence. As the demand for massive computing power continues to increase, the HPC community is striving to develop larger computing systems in pursuit of the power of scale. Nowadays,  
a race among various countries is underway to build the world's first exascale supercomputer 
to accelerate scientific discoveries, big data analytics, etc. It is expected that the first exascale supercomputer will enter service by 2020. 
However, making the transition to extreme-scale poses numerous unavoidable scientific and technological challenges.


As today's HPC and Cloud Computing systems grow to 
meet tomorrow's compute power demand, two of the biggest challenges will be system resilience and power 
consumption, both being direct consequences of the dramatic increase in the number of system components~\cite{exa_challenge_2010,snir2014addressing}. Regardless of the reliability of individual component, the system level failure rate will continue to increase as the number of 
components increases, possibly by several orders of magnitude. It is projected that the Mean Time Between Failures (MTBF) of future extreme-scale systems will be at the order of hours or even minutes, meaning 
that many failures will occur every day~\cite{Bergman08exascalecomputing}. Without an efficient fault tolerance mechanism, faults will be so frequent that the applications running on the 
systems will be continuously interrupted, requiring the execution to be restarted from a previous point for every failure. 

Also thanks to the continuous growth in system components, there has been a steady rise in power consumption in large-scale distributed systems. 
In 2005, the peak power consumption of a single supercomputer reached 3.2 Megawatts. This number was doubled only after 5 years, and reached 17.8 
Megawatts with a machine of 3,120,000 cores in 2013. Recognizing this rapid upward trend, the U.S. Department of Energy has set 20 
megawatts as the power limit for future exascale systems, 
turning power from an optimzation goal to a leading system design constraint. 

Today, two classic approaches to fault tolerance are dominant. The first approach is rollback recovery, which rolls back and restarts the execution 
every time there is a failure. This approach is often equipped with checkpointing to periodically save the execution state to a 
stable storage so that execution can be restarted from a recent checkpoint in the case of a failure~\cite{Elnozahy:02:Survey,kalaiselvi_sadhana_2000,Chandy:1985:DSD:214451.214456}. On the other hand, the second approach, referred to as process replication, exploits hardware redundancy and executes multiple instances of the same task 
in parallel to overcome failure% and guarantee that at least one task instance reaches completion
~\cite{bartlett_1981_nonstop,tsai_isads_2011,ferreira_sc_2011}. 


However, neither of the above two approaches applies well to future extreme-scale systems. Checkpointing/restart lacks of forward progress, meaning that its efficiency drops as failure rate increases. Given the anticipated increase in system level failure rates and the time to checkpoint large-scale 
compute-intensive and data-intensive applications, the time required to periodically checkpoint an application 
and restart its execution will approach the system's MTBF~\cite{Cappello:2009:TER:1640402.1640428}. On the other hand, process replication has a low system efficiency (no more than 50\%) by default because of its need for dedicated resources for replica processes. Therefore, should an exascale system be built in the next few years with any of the two fault tolerance approaches, a large portion of its capacity would be wasted due to fault tolerance. Furthermore, neither of them addresses the power cap issue. 

To address the above shortcomings, we proposed Lazy Shadowing as an adaptive and power-aware approach to achieve high-levels of resilience in extreme-scale, failure- prone computing environments. Lazy Shadowing is a novel computational model that goes beyond adapting or optimizing well known and proven techniques, and explores radically different methodologies to fault tolerance~\cite{cui_2016_scalcom}. 
The basic tenet of Lazy Shadowing is to associate with each main process a suite of “shadows” whose size depends on the 
``criticality" of the application and its performance requirements. Each shadow process is an exact replica of the original 
main process, 
and a consistency protocol is used to assure that the main and the shadow are consistent.  
When possible, the shadow executes at a reduced rate to save power.
Lazy Shadowing achieves QoS along with power awareness by dynamically responding to failures. Experimental results demonstrate that Lazy Shadowing achieves higher performance and significant energy savings compared to existing approaches in most cases. 

Recently, however, several limitations of Lazy Shadowing have been identified. Firstly, Lazy Shadowing can only tolerate one failure per shadowed set. As a result, failures, as they occur, reduce the vulnerability of the system.  Secondly, shadows are substitutes for mains, increasing the implementation complexity to deal with failures. %Thirdly, fata sharing through inherence of objects, such as sockets, increases the complexity of dealing with failures when they occur. 
Thirdly, the assumsion of crash failures limits the efficiency of Lazy Shadowing. 

In this paper, we present our latest work on addressing the above limitations. Firstly, we combine dynamic process creation with shadow leaping to efficiently keep the system from becoming vulnerable. Then, we deviate from the concept of shadow as a replica, where a shadow is promoted to a new main when the original main fails, and use shadow as an ``assistant" to a main whereby a shadow helps a main to overcome failures until the main completes execution. Last but not least, for different types of failures, we study different schemes to optimize Lazy Shadowing. The main contributions of this paper are as follows:

\begin{itemize}
\item An enhanced scheme of Lazy Shaodwing that incorporates rejuvenation techniques for consistent reliability and improved performance.
\item A full-feature implementation for Message Passing Interface
\item A through evaluation of the overhead and performance of the implementation with various benchmarks and real applications.
\end{itemize}

The rest of the paper is organized as follows. We begin with a survey on related work in Section 
\ref{sec:related_work}. Section \ref{sec:design} introduces system design and fault model, followed by discussion on implementation details in Section \ref{sec:implementation}.
Section \ref{sec:evaluation} presents empirical evaluation results. Section \ref{sec:conclusion} concludes this work and points out future directions.



