The computational model of Lazy Shadowing has been continuously optimized to improve its scalability and efficiency, to eliminate vulnerability, and to reduce implementation complexity and overhead. This section presents the system design of the comprehensive Lazy Shadowing model. 

\subsection{Fault model}
 
As demonstrated in~\cite{cui_2016_scalcom}, Lazy Shadowing is able to tolerate both hardware and software failures under the fail-stop fault model. In this work, we continue with the assumption of fail-stop model. In order to further improve resilience and efficiency, however, we differentiate between temporary failures and permanent failures. Temporary failures include memory bit flips, kernel panic, etc., and can be recoverd by rebooting the machine, while permanent failures, such as failure in power supply and network switch, needs the device to be replaced in order to recover. Later in this paper we will show that Lazy Shadowing maximizes the resource utilization for resilience by adopting different schemes for different types of failures. 

\subsection{Shadowing}

Shadowing is the essential concept in  Lazy Shadowing. With shadowing, each original process (referred to as main) is associated with a replica process (referred to as shadow) that executes at a potentailly lower rate to save power. Then fault tolerance comes from the property that if one process fails, its associated process can continue to complete the task. For example, if a main process fails, its shadow is promoted to a new main and continue to carry out the assigned task. In this way, shadow processes are substitutes for mains in the case of failure. In this work, we deviate from the original concept of shadow as a replica and use a shadow as ``assitant" to a main to complete computation in the presence of failures. Specifically, if a main fails, a new main process will be rejuvenated from its associated shadow by our leaping technique (discussed below), while the shadow remains a shadow. 

\subsection{Leaping}

Leaping is initially proposed as a technique to boost performance in \cite{cui_2016_scalcom}. As the shadows execute slower than mains, failure recovery will introduce delay to the execution. Leaping opportunistically takes advantage of the recovery time and copies state from healthy mains to their associated shadows. As a result, shadows achieve forward progress with minimal overhead, and recovery time for future potential failures is minimized.

Recently, we have identified an empirical problem to which leaping is a solution. When Lazy Shadowing is used to execute an MPI application, application messages are generated at the rate of the mains, but consumed by the shadows at a lower rate because the shadows are slower. As a result, messages accumulate on the shadow side and could possibly result in a buffer overflow. Leaping is naturally a solution to this problem as it can move the shadows forward and synchronize their execution states with those of the mains. After the synchronization, accumulated messages at the shadows become obsolete and thus can be safely discarded. To differentiate the two cases where leaping is used, leaping during failure recovery is referred to as failure induced leaping while leaping to avoid buffer overflow is referred to as forced leaping. 

\subsection{Rejuvenation}

It has been discussed in ~\cite{cui_2016_scalcom} that with shadow collocation each shadowed set can only tolerate one failure. After the first failure, all main processes in the shadowed set would lose their shadows and become vulnerable. Although quantitative study show that a second failure in a shadowed set is unlikely to occur even with over one million processes, in practice the system will become more and more vulnerable as failures occur. In many cases, it would be too costly to take such risk, especially for long-running, large-scale, and mission-critical applications. Therefore, it is preferable to maintain the same level of resilience across failures.

Not surprisingly, vulnerability could be avoided by creating a new process for every failed process (either main or shadow). In this way, every main is always guaranteed to have an associated shadow and shadow does not need to substitute a main. The problem, however, is that the newly created process will start from the beginning and may lag far behind the other processes in the system. Later on when the new processs needs to participate in a synchronization point or when it need to perform a failure recovery, significant delay will incur as a result of its lag. Fortunately, leaping can be used to deal with this issue. After a new process is created, we can use leaping to synchronize the new process' state with the existing one. Consider a pair of main process, $M$, and shadow process, $S$. If $M$ fails, a new main process will be created to replace $M$, and then a leaping from $S$ will advance the new process to the state of $S$. On the other hand, if $S$ fails, a new shadow process will be created and immediately advanced to the state of $M$ by leaping. 

Depending on the type of failure, the new process will be placed at different locations. If it is a temporary failure, the node where failure occurs will be rebooted and then used to host the new process, whether it is a main or shadow. Although there is a delay from the rebooting, it is usually acceptable and can be accounted part of the recovery. 
For permanent failures, the node cannot be used and we have to migrate and collocate some processes. If the new process is a main, its existing shadow will be migrated to another node where shadow process(es) reside, and make room for the new main. Otherwise, if the new process is a shadow, it will be directely created on a shadow node. 