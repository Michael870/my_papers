HPC and Cloud are two ecosystems that are designed for different applications and with disparate design principles. However, Big data technologies, such as Hadoop, clustered storage, and data visualization, are now merging with traditional HPC technologies. 
On the one hand, an increasing portion of HPC workloads is becoming data intensive.
On the other hand, Big data applications are requiring more and more computing power. 
As the boundaries between Cloud and HPC continue to blur, it is clear that there is an urgent demand for a systematic computational model that adapts to the computing platform and accommodates the underlying
workloads. SO WE NEED ADPATIVE SHADOW.



Current fault tolerance approaches rely exclusively on either time or hardware redundancy to hide failures from being seen by users. 
Rollback recovery, which exploits time redundancy, requires full or partial re-execution when failure occurs.  
Such an approach
can incur a significant delay, % subjecting cloud service providers to SLA violations,
and high power costs due to extended execution time.
On the other hand, Process Replication relies on hardware redundancy and executes multiple
instances of the same task in parallel to guarantee completion with minimal delay. 
This solution, however, requires a significant increase in hardware resources and increases the power consumption proportionally. 

The system scale needed to solve the complex and urgent problems that our society will be facing is going beyond the scope of existing 
fault tolerance approaches. This thesis builds on top of the shadow replication fault-tolerant computational model, and 
devises novel techniques to simultaneously address the power and resilience challenges for future extreme-scale systems while guaranteeing system efficiency and application QoS. 
A combination of modeling, simulation, and experiments will be used to test the viability of the proposed ideas. The proposed work will be completed following the timeline shown in 
Table~\ref{tab:timeline}.








