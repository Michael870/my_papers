%Enabling Lazy Shadowing for resiliency in extreme-scale computing 
%brings about a number of challenges and design decisions that need to be addressed, including the applicability of this concept to a large number of 
%tasks executing in parallel, and the runtime mechanisms and 
%communications support to ensure efficient interaction between a 
%main and its shadow.
%In the following, we first introduce the basic Lazy Shadowing resilience model. We then %focus on resilience in extreme-scale computing environments, where a large number of %communicating tasks execute in parallel to complete a job. 
%To achieve high tolerance to failure and reduce energy consumption in these environments, we %propose \emph{Leaping Shadows}, an instance of Lazy Shadowing. The main property of the %leaping shadows resilience model is its ability to sustain forward progress in the presence %of failures.
%. referred to as \emph{leaping shadows}, 
%a technique referred to as \emph{shadowed set rejuvenation} to reduce application failure probability, and 
%\emph{leaping shadows}, 
%as an 
%efficient, forward-progress preserving model to achieve high tolerance to failure, while reducing energy consumption, in these environments. 

 %We also discuss the runtime design issues
%related to enabling runtime support to efficiently achieve 
%the expected levels of resilience in extreme-scale systems. 

%This is to test referring Subsection \ref{frame_single}.



%\subsection{Application characteristics}
%\label{frame_app}
%\input{Framework/application}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%\input{Framework/multiple}
Lazy shadowing provides the basis for the design of efficient energy- and power-aware fault-tolerance approaches, that takes the energy-delay tradeoffs of the underlying application into consideration. In this section, we show how Lazy Shadowing can be used as the basic building block for the design of a resilience model for extreme-scale computing environments. The resulting model, referred to as {\it Leaping Shadows}, takes into consideration the main characteristics of compute-intensive and highly-scalable applications to achieve high-tolerance to failure, while reducing energy consumption, in extreme-scale and failure-prone computing environments. In the following, we first introduce the execution and communication model of the targeted applications. We then describe the dynamics of the {\it Leaping Shadows} resilience model. Lastly, we discuss important aspects of its implementation. 

\subsection {System model}

We consider the class of compute-intensive and strongly-scaled applications, executing on a large-scale multi-core computing infrastructure~\cite{doe_ascr_exascale_2011}. Communication between cores is achieved using low-latency, high-bandwidth interconnect networks, such as Infiniband. 

We use $W$ to denote the size of an application workload, and assume that the workload is split  arbitrarily into a set of tasks, $\tau$, which execute in parallel and are synchronized using barriers. Given the prominence of MPI in HPC environments, we assume message passing as the communication model between tasks. Based on this model, each pair of communicating tasks is associated with a logical first-in-first-out (FIFO) channel, which guarantees ordered delivery of messages.

Assuming the maximum speed of a core is $\sigma_{max}=1$, the failure-free completion time of the application is $w = W/|\tau|$, when all the tasks execute in parallel. When a failure occurs, the non-failing tasks continue executing until they reach their synchronization barrier. These tasks remain idle until the failure recovery is complete. 
%resulting in performance hiccups~\cite{muller2010}, especially for tightly-coupled applications. 
The main objective of the Leaping Shadows resilience model is to minimize the idle time induced by failures, 
%mitigate the impact of performance hiccups, 
and ensure forward progress by rolling-forward the shadows whose associated mains are still alive, during the recovery phase. In Section~\ref{anal_time}, we will show that the impact of failures is well bounded as a result of forward leaping, even for tightly-coupled applications.


%\subsection{Shadow collocation}




\subsection {Leaping Shadows}

The execution of an application can be carried out by simultaneously running all main and shadow processes for all the tasks. Let $m_i$ denote the main process executing the $i^{th}$ task $task_i$ of the application, and $s_i$ its associated shadow. The task execution is divided into a set of execution phases, each extending over a synchronization interval. In the absence of failure, the behavior of a main  and its leaping shadow is identical to the behavior of a main and its lazy shadow, depicted in Figure \ref{fig:sync}. Figure~\ref{fig:leap} shows the behavior of the main processes and their associated leaping shadows, assuming a failure occurrence at time $t_f$. 


\begin{figure}[!t]
	\begin{center}
        \subfigure[Faulty task behavior.]
        {
            \label{fig:faulty_leaping}
            \includegraphics[width=0.45\columnwidth]{Figures/jump1}
        }
        \subfigure[Non-faulty task behavior.]
        {
            \label{fig:non_faulty_leaping}
            \includegraphics[width=0.45\columnwidth]{Figures/jump2}
        }
	\end{center}
	%\vskip -0.25in
	\caption{The concept of Leaping Shadows.}
	\label{fig:leap}
\end{figure}

Figure~\ref{fig:leap}(a) depicts the execution dynamics of the failing main and its associated shadow. Upon failure of the main process, the associated shadow continues execution, but at a higher rate, to minimize the impact of failure recovery on the application's progress. 
Figure~\ref{fig:leap}(b) illustrates the behavior of the remaining main processes and their associated shadows. Unaware of the failed process, the remaining main processes continue executing until they reach their synchronization barriers at time $t_{sync}$. While the shadow of the failed main process progresses toward its synchronization barrier, all remaining main processes become idle until time $t_r$. %It is worth noting that, given the tightly-coupled and strongly-scaled nature of the application, synchronization points occur frequently. Consequently, the time between synchronization points is very small relative to the total execution time of the application. Therefore, if one main, $m_i$, fails at 
%time $t_f$, the remaining main processes will reach their synchronization point, shortly after the failure, specifically at at time $t_{sync} = t_f +\epsilon$, 
%where $\epsilon \approxeq 0$. 
The Leaping Shadows model opportunistically takes advantage of the idle time, induced by failure recovery, to {\it leap forward} the shadows to their associated non-failing main processes. 
After the shadow of the failing main reaches its synchronization barrier, all processes resume execution from a consistent synchronization point. This process continues until the completion of all tasks. Forward leaping increases the shadow's rate of progress, at a minimal energy cost. Consequently, it reduces significantly the likelihood of a shadow falling excessively behind its associated main, thereby ensuring fast recovery, upon failure, while minimizing energy consumption.

Collocation is used to control the leaping shadows execution rates. To execute an application with $M$ tasks, $M+S$ cores are required, where $M$ is a multiple of $S$, all executing at the maximum rate. $M$ of these cores are allocated to the main processes while the remaining $S$ cores are shared among their associated shadows. Each main process is allocated one core, while $\alpha=M/S$ shadows are collocated on a single core. $\alpha$ is referred to as the main to shadow ratio. For example, if $M=9$ and $S=3$, then the 9 shadows share 3 cores, with every $\alpha=3$ shadows collocated on each core, as shown in Figure~\ref{fig:sc_mapping}.
  
Collocation of $\alpha$ shadows on a core has an important ramification with respect to the resilience of the system. Specifically, to speed up a shadow 
of a failed main to the maximum rate, all other collocated shadows must be terminated. Consequently, a second failure in any of the mains of the terminated shadows cannot be tolerated. In other words, the $M+S$ cores are grouped into $S$ sets, which we call \emph{shadowed sets}, each containing $\alpha+1$ cores with $\alpha$ mains executing on $\alpha$ cores (referred to as main core) and their corresponding $\alpha$ shadows collocated on one core (referred to as shadow core). Each shadowed set can tolerate a failure in any of its cores, since failure of a main core would be tolerated by the shadow core and failure of the shadow core will not affect any main core. After the first failure in a shadowed set, the set is called \emph{vulnerable} because it cannot tolerate another failure. %In the following subsection, we will discuss a rejuvenation scheme that deals with vulnerable shadowed sets.

\begin{figure}[!t]
  \begin{center}
    \includegraphics[width=0.7\columnwidth]{Figures/sc_mapping.pdf}
  \end{center}
  %\vskip -0.25in 
  \caption{An example of collocation. $N=12$, $M=9$, $S=3$, and $\alpha=3$.}
  \label{fig:sc_mapping}
\end{figure}





\begin{algorithm}[t]
  \SetKwInOut{Input}{input}
  \SetKwInOut{Output}{output}
  \caption{Leaping Shadows}
  \Input{$W, M, S$}
  \Output{Application execution status}
  \BlankLine
  split $W$ into $M$ tasks\; \nllabel{line:split} 
  assign $M$ tasks to $S$ shadowed sets\; \nllabel{line:cluster} 
  %$T_l \leftarrow T+t_{now}$\;%, $C_{vul} \gets 0$
  start $m_i$ and $s_i$ for each $task_i$\;
    \While{execution not done}
    {
        \If{failure detected in $ss_j$} %\nllabel{line:if_start_1} 
        {
            \nllabel{line:if_start_1} 
            \eIf{$ss_j$ is vulnerable}
            {
                notify ``Application failure"\;
                terminate all mains and shadows\;
                repair all failures\;
                restart execution\; %\Comment{re-execution}
            }
            {
                mark $ss_j$ as vulnerable\;
                %\State $C_{vul} \gets C_{vul} + 1$
                %\If{$C_{vul} == V$}
                %    \State perform shadowed set rejuvenation   
                %\EndIf 
                \If{failure happened to $m_k$} 
                {
                    promote $s_k$ to $m_k$\;
                    perform forward leaping\; %failure induced shadow leaping
                    %$T_l \leftarrow T+t_{now}$\;
                }
            }
        }  
        \nllabel{line:if_end_1}
        %\If{$t_{now} \ge T_l$} %
        %{
        %    \nllabel{line:if_start_2} 
        %    perform shadow leaping\;
        %    $T_l \leftarrow T+t_{now}$\;
        %    \nllabel{line:if_end_2}
        %} % 
        %\nllabel{line:if_end_2}
    }
    output ``Application completes"\;
  \label{al:ls}
\end{algorithm}

The basic steps describing the execution of an application, when using Leaping Shadows based on shadow collocation, are depicted in Algorithm 1.
To use $M+S$ cores to execute the application, the total workload is split into $M$ parallel tasks (line~\ref{line:split}), %, which are executed simultaneously by $M$ main processes and $M$ shadow processes. 
 which are then assigned to $S$ shadowed sets, each with $\alpha=M/S$ cores for $\alpha$ main processes and 1 core for all the associated shadow processes (line 2).  
%The $M$ shadows are then clustered into $S$ groups, each containing $\alpha=M/S$ shadows. 
The execution starts by simultaneously running all the main and shadow processes (line 3).
During the execution of the application,
the system runs a failure monitor that triggers corresponding actions when a failure is detected (line~\ref{line:if_start_1} to~\ref{line:if_end_1}). A failure may trigger different actions, depending on its type and precedence with respect to other failures.  A shadowed set becomes {\it vulnerable} after the occurrence of the first failure in the set. A failure occurring in a vulnerable shadowed set ($ss_j$), results in an application failure. In response, the system terminates all running 
processes, initiates a recovery phase, either by rebooting or replacing failing cores,  and restarts execution (line 8 to 10). %(this assumes that checkpointing is not used). 
On the other hand, failure in a non-vulnerable shadowed set
can be tolerated and does not translate into an application failure. In this case, the shadowed set in question ($ss_j$) is marked as vulnerable (line 12). Note, however, that a failure of a main process has different impact from that of a  shadow process.  While a shadow 
failure does not impact the normal execution of the main processes, and thus can be ignored, failure of the main process forces the remaining main processes to suspend execution after they reach their synchronization point.  The shadow process, $s_k$, associated with the failing process, $m_k$,  becomes the primary process of the associated task and increases its execution to the maximum rate (line 14). This, in turn, forces the termination of all other collocated processes.  Simultaneously, a forward leaping is undertaken by all remaining shadows to align their states with those of their associated mains (line 15).  
This process continues until the application is successfully completed.

\subsection{Leaping Shadows implementation issues}

%\subsection{Shadowed set rejuvenation}
%\label{frame_reju}
%\input{Framework/reju}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


State consistency is required both during normal execution and following a failure of a main process to roll-forward the state of the leaping shadows. During normal execution, shadows remain mute, in the sense that 
all outgoing messages from shadows are suppressed. 
A shadow process, however, will typically lag behind its main process during execution. Therefore, it is necessary to ensure that the shadow's state is consistent with that of its associated main, to successfully complete its associated task in case of failure. To this end, a message-logging protocol is used to ensure consistency~\cite{Marz}. These protocols typically use a minimum amount of meta-information to store and replicate the non-deterministic decisions in the execution of an application.  These meta-data, also called determinants, are exchanged through system-level messages. To provide correct recovery after failure, 
a mechanism is required to guarantee that every shadow process follows the same computation and communication steps as its main process. 
After a main process $m_i$ fails, $s_i$ will take over $m_i$'s role to recover from this failure. If there are other shadows sharing the same core with $s_i$, they will be terminated and $s_i$ will start consuming the messages in its receiver-side message log at a faster speed. The message logging protocol will ensure that shadow $s_i$ reaches a consistent state with the rest of the system. 

Upon failure of a main processes, shadow processes will update their address space to ``catch up" with their associated non-failing main processes. A technology, such as remote direct memory access (RDMA), can be used to roll-forward the state of the shadow to be consistent with that of its associated main. Rather than copying data to the buffers of the operating system, RDMA enables the network adapter to transfer data directly from the main process to its shadow. The zero-copy networking feature of RDMA considerably reduces latency, thereby enabling fast transfer of data between the main and its shadow.

 


