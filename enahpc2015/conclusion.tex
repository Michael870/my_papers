
The major contribution of this paper is a new technique, called
``shadow computing'' that provides energy-aware fault tolerance in
large-scale distributed computing environments. We also presented
details on the shadow computing execution model and showed the
feasibility of implementing such a system in distributed computing
environment. We then explored different methods for applying this model
to a high performance computing environment. Through this exploration
we develop a general framework for evaluating the energy consumption
of process replication schemes. Using this energy model we then
analyzed our proposed solutions.

We proposed three different schemes for applying ``shadow computing''
to the high performance computing environment. Through evaluating the
expected energy consumption of those schemes we showed that ``shadow
computing'' has the ability to save significant energy. The energy
savings is highly dependent upon the laxity available in the event of
failure, represented as $\alpha$ in our analysis. We then showed that
other factors such as component MTBF and task size have a minimum
impact on the energy consumption. Furthermore, we demonstrated that
simple, low-cost schemes such as stretched and minimum work
replication can achieve near optimal behavior.
