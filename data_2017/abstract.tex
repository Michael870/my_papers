As the boundaries between HPC and Big Data analytics continue to blur, it is clear that there is an urgent need for a systematic computational model that understands the computing platform and adapts to the underlying workloads. At the same time, power awareness and fault tolerance have become major concerns as computing systems continue to scale out to satisfy the increasingly large demands on computing capacity. This paper proposes a novel computational model that adapts to both compute- and data-intensive workloads, and deal with diverse types of faults. Evaluation results demonstrate that the proposed model is able to achieve significant energy savings compared to current replication techniques, while maintaining the same level of fault tolerance.